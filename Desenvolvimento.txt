- um computador digital pode simular um neurocomputador, e, por meio de mecanismos de otimização e de simulação de todas as possibilidades operacionais 

   factiveis (possibilidade de resolver problemas que são computacionalmente soluveis) pra o neurocomputador, fornecer garantias formais de confiabilidade na

  na solução de problemas;



-neurocomputador tem um hardaware dedicado


- programar um neurocomputador em uma arquitetura de rede de hopfield não envolve a elaboração de um programa executado por uma sequencia de instruções.

- pelo contrário, busca-se pela rede de hopfield delimita o problema em um espaço de estados do neurocomputador, conduzindo a uma superficie de energia a ser minimizada
   com base da dinãmica de relaxação produzida pelo acoplamento entre os neuronios


%%%%%% RBF 

-camada intermediária - modelo não linear pq a função base radial é linear
 
 -treinamento por metodos quadraticos

- função de ativação base radial cresce/decresce monotonicamente com distancia a um ponto central 


- modelo de regressão linear parametros centro/taxa de dispersao constantes


- função base radial/ são funções não lineares

- modelo de regressão resultante ser linear ou não nos parametros : possibilidade de ajuste os centros e as dispersões das funções 

-se somente os pesos da camada de saída formarem o conjutno de parametros ajustavéis, a rede é linear nos parametros 

- pode utilizar o aprendizado supervisionado na última camada (backpropagation) 

-- na rbf minimos locais tem uma influencia bem maior e sugere evitar este mecanismo de ajuste


-- CAMADA INTERMEDIÁRIA --TREINAMENTO NÃO SUPERVISIONADO/ AUTOORGANIZADO (QUANTIZAÇÃO VETORIAL OU ALGORITMO DE TREINAMENTO COMPETITIVO) 


-- CAMADA DE SAIDA ( TÉCNICAS COMO PSEUDO-INVERSÃO E OLS( ORTHOGONAL LEAST SQUARES)


-- CAPACIDADE DE APROXIMAÇÃO UNIVERSAL -- NÚMERO SUFICIENTE DE NEURONIOS COM FUNÇÃO DE BASE RADIAL QUALQUER FUNÇÃO CONTÍNUA DEFINIDA EM UMA REGIÃO COMPACTA PODE SER DEVIDAMENTE APROXIMADA USANDO UMA REDE RBF
  

-- REDES COM CAPACIDADE DE APROXIMAÇÃO LOCAL SÃO BASTANTE EFICIENTES QUANDO A DIMENSÃO DO VETOR DE ENTRADA É REDUZIDA 

    ISSO PQ COM O AUMENTO DO VETOR DE ENTRADA DEVE-SE AUMENTAR O NÚMERO DE FUNÇÃO BASE RADIAL DE FORMA EXPONENCIALMENTE O QUE CAUSA O AUMENTO 
    DO CUSTO COMPUTACIONAL



%%%% DIFERENÇAS ENTRE RBF E MLP 


-- REDES DE APRENDIZADO LOCAL  


%% MLP REDES DE APRENDIZADO GLOBAL POR CAUSA DAS RIDGES FUNCTIONS (FAZEM APROXIMAÇÃO DE EFEITO GLOBAL) 
    MLP APRESENTA MAIOR CAPACIDADE DE GENERALIZAÇÃO SE O VETOR DE ENTRADA FOR MAIOR

-- POSSUI SOMENTE UMA UNICA CAMADA INTERMEDIÁRI / MLP PODE TER QUANTAS FOREM NECESSSÁRIOS
-- NEURONIOS DE SAIDA SÃO SEMPRE LINEARES 
 
-- NEURONIOS DA CAMADA INTERMEDIARIA TEM UMA FUNÇÃO BASE RADIAL

-- A ATIVAÇÃO INTERNA DO NEURONIO DA CAMADA INTERMEDIÁRIA SE DÁ NORMA PONDERADA DA DIFERENÇA ENTRE A ENTRADA E O CENTRO
   %% MLP ( ATIVAÇÃO É DADO PELO PRODUTO INTERNO ENTRE O PESO DA CAMADA INTERMEDIÁRIA E O VETOR DE ENTRADA)


---CRITÉRIO/ NUMERO FIXO E PREVIAMENTE ESPECIFICADO DE CENTROS 
  1- ESPALHAR OS CENTROS UNIFORMEMENTE AO LONGO DA REGIAÃO EM QUE SE ENCONTRAM OS DADOS 
 2- ESCOLHER ALEATORIAMENTE UM SUBCONKUNTO DE PADROES DE ENTRADA COMO CENTROS
3- AUTO-ORGANIZAR OS CENTROS DE ACORDO COM A DISTRIBUIÇAÕ DOS DADOS DE ENTRADA



-- CRITERIO DISPERSÃO 
  USA-SE UMA UNICA DISPERSÃO PARA TODOS OS CENTROS 


--SELEÇÃO DOS CENTROS POR AUTO-ORGANIZAÇÃO 
   AUTOORGANIZAR OS CENTROS, ALGORITMO CAPAZ DE REFLETIR A DISTRIBUIÇÃO DOS DADOS DE ENTRADA 
    ALGORITMO DE CLUSTERIZAÇÃO KMEANS
    SUJEITO A INFLUENCIA DE MINIMOS LOCAIS
    SIMILAR AO APRESENTADO PELA REDE DE KOHONEN




%% CAPACIDADE DE APROXIMAÇÃO UNIVERSAL-- AFIRMA QUE DADO UM CERTO NUMERO DE NEURONIOS E UMA CERTA CONFIGURAÇAÕ DE PESOS SINAPTICOS 
   QUE PERMITEM OBTER UM ERRO DE APROXIMAÇÃO ARBITRARIAMENTE BAIXO PARA OS DADOS DE TREINAMENTO SUPONDO QUE SE CONSIDERA UMA REGIAO
    COMPACTA DO ESPAÇO DE ENTRADA E QUE O MAPEAMENTO ORIGINAL É AMOSTRADO PARA PRODUZIR OS DADOS DE TREINAMENTO DEVE SER CONTINUO.


%% QUANTO MAIOR O NÚMERO N DE NEURONIOS NA CAMADA INTERMEDIARIA MAIOR É A FLEXIBILIDADE DO MODELO MATEMÁTICO RESULTANTE, OU SEJA, MAIORES SÃO 
   " POSSIBILIDADES DE CONTORÇÃO " DO MAPEAMENTO A SER APROXIMADO 


%% MÁXIMA CAPACIDADE DE GENERALIZAÇÃO ESTÁ ASSOCIADA A MODELOS OTIMAMENTE REGULARIZADOS, OU SEJAM QUE SE CONTORCEM NA MEDIDA CERTA ( EXIBEM CERTO 

 GRAU ADEQUADO DE FLEXIBILIDADE DE ACORDO COM A DEMANDA DE CADA APLICAÇÃO 



%% TRABALHOS -- CONTROLAR A NORMA DOS PESOS SINAPTICOS É MAIS RELEVANTE PARA A CAPACIDADE DE GENERALIZAÇÃO DO QUE CONTROLAR O TAMANHO DA REDE
   NEURALOU SEJA O NUMERO DE NEURONIOS NA CAMADA INTERMEDIARIA 












%% REDES ELM/ MÁQUINAS DE APRENDIZADO EXTREMO 

-- RESPONSABILIDADE DE GARANTIR UMA BOA CAPACIDADE DE GENERALIZAÇÃO AOS PESOS DA CAMADA DE SAIDA 


-- PESOS DA CAMADA INTERMEDIÁRIA PODEM SER DEFINIDOS ALETAORIA DE ACORDO COM UMA CERTA DISTRIBUIÇAÕ DE PROBABILIDADE

-- TREINAMENTO LINEAR NOS PARAMETROS AJUSTAVEIS ( ECONOMIA EXPRESSIVA DE RECURSOS COMPUTACIONAIS PARA EFETUAR O TREINAMENTO SUPERVISIONAOD)

--- CAPACIDADE DE GENERALIZAÇAO MAXIMIZADA PELO CONTROLE DOS PESOS NA CAMADA DE SAÍDA, NÃO DEPENDENDO DO NÚMEROS DE NEURONIOS NA CAMADA INTERMEDIARIA (COMO MLPS)

-- HÁ RECURSOS COMPUTACIONAIS DÍSPONIVEIS PARA IMPLEMENTAR REDES NEURAIS SOBREDIMENSIONADAS

-- FUNÇÇÕES BASES PODEM SER ARBITRARIAS( RADIAL OU RIDGE FUNCTIONS) ( MLP- RIDGE FUNCTIONS / RBF FUNÇÃO BASE RADIAL

-- PROCESSO DE OTIMIZAÇÃO  RIDGE FUNCTIONS



-- REGULARIZAÇÃO PARA FUNÇÕES UNIDIMENSIONAIS  K VIZINHOS PROXIMOS, SPLINES POLINOMIAIS SUAVIZANTES, POLINOMIOS DE HERMITE COM UM NÚMERO REDUZIDO 



-- REGULARIZAÇÃO PARA FUNÇÕES DE CASO MULTIDIMENSIONAL 
    LASSO -- VANTAGEM NO FATO DE MULTIPLOS TERMOS DO VETOR PESO SE ANULAREM, O QUE REPRESENTA UM PROCESSO DE SELEÇÃO DE VARIAVEIS E LEVA A MODELOS DE APROXIMAÇÃO MAIS PARCIMONIOSOS
           -- PERMITE JUSTIFICAR A ANULAÇÃO DE UM SUBCONJUNTO DE PARAMETROS AJUSTAVEIS 
    ELASTIC SOLUÇAO INTERMEDIARIA ENTRE RIDGE REGRESSION EO LASSO


-- NEURÔNIOS: CELULAS ENCAPSULADAS POR MEMBRANAS, PEQUENAS ABERTURAS NESTAS MEMBRANAS ( CANAIS) PERMITEM A TRANSFERENCA DE INFORMAÇÃO ENTRE ELES 

QUANDO UM POTENCIAL DE AÇÃO CHEGA AO TERMINAL DE UM AXONIO, ELE ESTIMULA VESICULAS QUE POR SUA VEZ PROMOVEM A LIBERAÇÃO DE NEUROTRANSMISSORES 
NA FENDA SINAPTICA, OS QUAIS SE DIFUNDEM E SE LIGAM A RECEPTORES NO 
  NEURONIO POS SINAPTICO 

 ESSA LIGAÇAO ENTRE OS NEUROTRANSMISSORES E RECEPTORES CONDUZ A ABERTURA DOS CANAIAS IONICOS, PERMITINDO ENTRADA E SAIDA DE IONS DA CELULA, 
EM RESPOSTA A DIFERENÇA DE POTENCIAL EXISTENTE.
  ESSE DESLOCAMENTO DE ÍONS PRODUZ UM PULSO ELÉTRICO 


 CADA TREM DE PULSO ELETRICO SE PROPAGA PELO NEURONIO POS SINAPTICO E OS PULSOS CHEAGM 


-- CELULA EM REPOUSO.. A PARTE INTERNA É MENOS POSITIVA DO QUE A EXTERNA HAVENDO NA PARTE INTERNA ( K +)  E NA PARTE EXTERNA ( NA+)

    PELA AÇÃO DOS NEUROTRANSMISSORES NA SINAPSE(LIBERAÇAO DOS NEUROTRANSMISSORES NA FENDA SE DIFUNDEM E SE LIGAM AOS RECEPTORES POS SINAPICO)

-- PELA AÇÃO DOS NEUROTRANSMISSORES NA SINAPSE, ABRE-SE OS CANAIS IONICOS, COM IONS DE SODIO ADENTRAM A PARTE INTERNA, PROMOVENDO UMA DIFERENÇA DE POTENCIAL
  DENOMINADA POTENCIAL DE AÇÃO 


--- COM ESTA ENTRADA DE IONS DE SODIO, O INTERIOR PASSA A SER MAIS POSITIVO QUE O EXTERIOR 

-- EM SEGUIDA IONS DE POTASSIO FLUEM PARA FORA DA CELULA RESTAURANDO A CONDIÇÃO DE INTERIOR MAIS NEGATIVO QUE EXTERIOR 



-- COM AS BOMBAS DE SODIO-POTASSIO, É RESTAURADA FINALMENTE A CONDIÇAÕ DE MAIOR CONCENTRAÇÃO DE IONS DE POTASSIO DENTRO DA CELULA E MAIOR CONCENTRAÇÃO DE ÍONS DE SODIO 
   FORA DA CELULA 

 --- SEGUE-SE UM PERIODO REFRATARIO, DURANTE O QUAL A MEMBRANA NÃO PODE SER ESTIMULADA, EVITANDO ASSIM A RETROPROPAGAÇÃO DO ESTÍMULO

- BOMBAS DE SODIO E POTASSIO: IONS DE SODIO QUE HAVIAM ENTRADO NO NEURONIO DURANTE A DESPOLARIZAÇÃO SÃO REBOMBEADOS PARA FORA DO NEURONIO MEDIANTE O FUNCIONAMENTO DA

DAS BOMBAS QUE EXIGEM GASTO DE ENERGIA 


PARA CADA MOLECULA DE ATP EMPREGADA NO BOMBEAMENTO,  3 IOONS DE SÓDIO SÃO BOMBEADOS PARA FORA E DOIS DE POTASSIO PARA DENTRO DA CÉLULA
























































&&&& 

 - parametros da função base ajustavéis e função base não linear- modelo nao linear e não linear nos parametros


 - vantagens dos modelos lineares no parametros= obter um conjunto de coeficiente da combinação linear
 de forma fechada por meio de tecnicas baseadas em quadrados mínimos 
- desvantangens dos modelos não lineares nos parametros= requer processo numericos iterativos (técnicas de otimização não linear para se obter a solução






%%% OBTENÇÃO DA SOLUÇÃO ÓTIMA -- METODOS DOS QUADRADOS MINIMOS 

- APLICAR A CONDIÇÃO DE OTIMALIDAE (RESTRIÇÕES ATENDIDAS PELOS PONTOS DE MÁXIMO E MÍNIMO DE UMA FUNÇÃO DIFERENCIAVEL) QUE PERMITE OBTER 
A SOLUÇÃO ÓTIMA DO PROBLEMA DE OTIMIZAÇAÕ   


- CONDIÇÃO DE OTIMALIDADE -- GRADIENTE SE ANULA NOS PONTOS EXTREMOS DA FUNÇÃO OBJETIVO 

1. DIFERENCIE A FUNÇÃO EM RELAÇÃO AOS PARAMETROS AJUSTAVEIS

2. IGUALE ESTAS DERIVADAS PARCIAIS A ZERO;

3. RESOLVA O SISTEMA LINEAR DE EQUAÇÕES RESULTANTES 



-- SISTEMA COM M EQUAÇÕES E M INCOGNITAS- DETERMINADO E COM SOLUÇÃO UNICA 

  TAL SISTEMA NÃO TERÁ SOLUÇÃO UNICA SOB CONDIÇÕES PATOLOGICAS -- A SOLUÇÃO UNICA É GARANTIDA SE CASOS OS CENTROS DAS
   FUNÇÕES DE BASE RADIAL NÃO SEJAM COINCIDENTES 

A MATRIZ H DEVE SER POSITIVA E SIMETRICA PARA EXISTE SUA INVERSA 
 SE SÓ A INVERSA DE H SE H TIVER POSTO COMPLETO( JÁ QUE VALE M<= N)




























 